\chapter[Học khái niệm trong logic mô tả sử dụng mô phỏng hai~chiều]{HỌC KHÁI NIỆM TRONG LOGIC MÔ TẢ\\SỬ DỤNG MÔ PHỎNG HAI CHIỀU} 
\label{Chapter3}
\thispagestyle{fancy}

%-------------------------------------------------------------------
\section{Giới thiệu}
\label{sec:Chap3.Introduction}
Trong những năm gần đây, logic mô tả đã và đang được ứng dụng trong nhiều lĩnh vực của Web ngữ nghĩa. Nó được xem là một thành phần quan trọng trong các hệ thống ngữ nghĩa và được sử dụng để biểu diễn cũng như suy luận tri thức trong các hệ thống này. Đặc tả các khái niệm phù hợp cho các hệ thống ngữ nghĩa là một trong những vấn đề rất được quan tâm. Do vậy, vấn đề đặt ra là cần tìm được các khái niệm quan trọng và xây dựng được định nghĩa của các khái niệm đó. Học khái niệm trong logic mô tả nhằm mục đích kiểm tra, suy luận và tìm ra được các khái niệm này để phục vụ cho các ứng dụng khác nhau như: tin sinh học, tin học trong y tế, quản trị tri thức, kỹ nghệ phần mềm,\,\ldots

Học khái niệm trong logic mô tả đã được nhiều nhà khoa học quan tâm nghiên cứu~\cite{Quinlan1990,Cohen1994,Lambrix1998,Badea2000,Iannone2007,Fanizzi2004,Fanizzi2008,Lehmann2007,Fanizzi2010,Lehmann2010,Nguyen2013}. Cùng với học khái niệm trong logic mô tả, các vấn đề liên quan đến học máy trong logic mô tả cũng được nhiều công trình đề cập đến~\cite{Alvarez2000,Kietz2003,Revoredo2010,Konstantopoulos2010,Distel2011,Lisi2012,Lisi2012B,Lisi2013,Ma2013}.

Quinlan nghiên cứu việc học các định nghĩa của mệnh đề Horn từ các dữ liệu được biểu diễn thông qua các quan hệ~\cite{Quinlan1990}. Tác giả đã đề xuất thuật toán \textsc{Foil} dựa trên ý tưởng khai thác tính hiệu quả của các hệ thống học thông qua thuộc tính và mở rộng nó cho các logic bậc nhất.

Trong một công trình nghiên cứu khá sớm về học khái niệm trong logic mô tả, Cohen và Hirsh đã nghiên cứu lý thuyết về khả năng học của logic mô tả \textsc{Classic} (một tiền thân của logic mô tả) và một logic con của nó là \textsc{C-Classic}~\cite{Cohen1994}. Các tác giả đã đề xuất thuật toán học khái niệm LCSLearn dựa trên các ``bao hàm chung nhỏ nhất''~\cite{Cohen1992}. 
%
Lambrix và Larocchia đã đề xuất một thuật toán học khái niệm đơn giản dựa trên việc chuẩn hóa khái niệm và lựa chọn khái niệm thông qua các thể hiện của dạng chuẩn hóa~\cite{Lambrix1998}. 

Badea và Nienhuys-Cheng~\cite{Badea2000}, Fanizzi cùng cộng sự~\cite{Fanizzi2004,Fanizzi2008}, Iannone cùng cộng sự~\cite{Iannone2007}, Lehmann và Hitzler~\cite{Lehmann2007,Lehmann2010} đã nghiên cứu học khái niệm trong logic mô tả bằng cách sử dụng các toán tử làm mịn ({\em refinement operators}) như trong lập trình logic đệ quy ({\em Inductive Logic Programming - ILP}).
%
Toán tử làm mịn trên xuống ({\em downward refinement operators}) của logic mô tả \ALER được thiết kế cho thuật toán học trên-xuống ({\em top-down})~\cite{Badea2000}. Trong quá trình tìm kiếm, các tác giả đã sử dụng dạng chuẩn của \ALER để đạt được các toán tử làm mịn đơn giản hơn.
%
Fanizzi và các cộng sự nghiên cứu toán tử làm mịn trên xuống trong logic mô tả \ALN~\cite{Fanizzi2004} và xây dựng hệ thống \textsc{DL-Foil}~\cite{Fanizzi2008}. Hệ thống này sử dụng một phiên bản mở rộng của thuật toán \textsc{Foil}~\cite{Quinlan1990}. Các thành phần chính của hệ thống sử dụng tập các toán tử làm mịn tương tự như trong~\cite{Badea2000}.
%

Ngoài việc sử dụng các toán tử làm mịn, các hàm tính điểm và chiến lược tìm kiếm cũng đóng vai trò quan trọng đối với các thuật toán đã được đề xuất trong các công trình này. Thuật toán DL-Learner~\cite{Lehmann2010} khai thác các kỹ thuật lập trình di truyền, còn thuật toán DL-FOIL~\cite{Fanizzi2008} khai thác dữ liệu không gán nhãn như trong học máy bán giám sát.
%

Iannone cùng cộng sự đã nghiên cứu về mô tả các khái niệm đệ quy theo phương pháp bán tự động và xây dựng các thuật toán suy luận trong logic mô tả \ALC~\cite{Iannone2007}. Ý tưởng chính của các thuật toán này là tìm và loại bỏ các phần của khái niệm có chứa lỗi phân loại.
%
Fanizzi và các cộng sự đã đề xuất cây quyết định thuật ngữ như một cấu trúc thay thế cho học khái niệm trong logic mô tả và một phương pháp dựa trên thuật toán đệ quy của cây trên-xuống chuẩn~\cite{Fanizzi2010}. Thuật toán có sử dụng các hàm tính điểm để phân lớp các cá thể trong giả thiết thế giới mở ({\em Open World Assumption - OWA})

Các công trình~\cite{Badea2000,Iannone2007} tập trung nghiên cứu vấn đề học khái niệm đối với cơ sở tri thức trong logic mô tả sử dụng ngữ cảnh~(1), trong khi đó các công trình còn lại giải quyết bài toán này trong ngữ cảnh~(2)~\cite{Fanizzi2004,Fanizzi2008,Lehmann2007,Lehmann2010}.

Lisi và Straccia đã trình bày một thuật toán mở rộng của \textsc{Foil}, có tên là \textsc{Foil-}$\mathcal{DL}$, cho việc học các tiên đề bao hàm tổng quát mờ từ các khẳng định chính xác dựa trên lập trình logic đệ quy~\cite{Lisi2013}. Revoredo cùng các cộng sự đã nghiên cứu việc học các khái niệm trong logic mô tả có xác suất từ dữ liệu quan hệ. Các tác giả đã đề xuất một thuật toán học trong logic mô tả có xác suất \textsc{cr}\ALC sử dụng các toán tử làm mịn và hàm tính điểm~\cite{Revoredo2010}.

Nguyen và Sza{\l}as đã áp dụng mô phỏng hai chiều trong logic mô tả để mô hình hóa tính không phân biệt được của các đối tượng~\cite{Nguyen2013}. Đây là công trình tiên phong trong việc sử dụng mô phỏng hai chiều cho việc học khái niệm trong logic mô tả. Trong công trình này, các tác giả đã đề cập đến xấp xỉ khái niệm bằng cách sử dụng mô phỏng hai chiều và lý thuyết tập thô của Pawlak~\cite{Pawlak1992,Pawlak2007}. 
Công trình của Nguyen và Sza{\l}as nghiên cứu bài toán học khái niệm cho các hệ thống thông tin dựa trên logic mô tả sử dụng ngữ cảnh~(3) trong logic mô tả \ALC với các tạo tử vai trò $\mI$ ({\em vai trò nghịch đảo}), $\mU$ ({\em vai trò phổ quát}) và các tạo tử khái niệm $\mO$ ({\em định danh}), $\mQ$ ({\em hạn chế số lượng có định tính}), $\Self$ ({\em tính phản xạ cục bộ của vai trò})~\cite{Nguyen2013}.
Tran cùng các đồng nghiệp~\cite{Tran2012}, Ha cùng các đồng nghiệp~\cite{Ha2012} đã mở rộng và tổng quát hóa công trình trên cho một lớp lớn hơn các logic mô tả bằng cách bổ sung các tạo tử khái niệm $\mF$ ({\em tính chất hàm}), $\mN$ ({\em hạn chế số lượng không định tính}). Ngoài ra, các công trình này cũng xem xét các thuộc tính (bao gồm thuộc tính rời rạc và thuộc tính liên tục) như là những phần tử cơ bản của ngôn ngữ.

Học khái niệm trong logic mô tả tương tự như việc phân lớp nhị phân trong học máy truyền thống. Tuy nhiên, việc học khái niệm trong ngữ cảnh logic mô tả khác với học máy truyền thống ở chỗ, các đối tượng không chỉ được đặc tả bằng các thuộc tính mà còn được đặc tả bằng các mối quan hệ giữa các đối tượng. Các mối quan hệ này là một trong những yếu tố làm giàu thêm ngữ nghĩa của hệ thống huấn luyện. Do đó, các phương pháp học khái niệm trong logic mô tả cần phải tận dụng được chúng như là một lợi thế.

Vấn đề học khái niệm cho cơ sở tri thức trong logic mô tả của đề tài này được đặt ra theo ngữ cảnh như~sau:

\noindent
\ramka{
Cho cơ sở tri thức $\KB$ trong logic mô tả $L$ và các tập các cá thể $E^+$, $E^-$. Học khái niệm $C$ trong $L$ sao cho:
	\begin{enumerate}
		\item $\KB \models C(a)$ với mọi $a \in E^+$, và
		\item $\KB \not\models C(a)$ với mọi $a \in E^-$,
	\end{enumerate}
	trong đó, tập $E^+$ chứa các mẫu dương và $E^-$ chứa các mẫu âm của $C$.
}

Chương này trình bày thuật toán {\em \BBCLearnS} ({\em \textbf{B}isimulation-\textbf{B}ased \textbf{C}oncept \textbf{L}earning for knowledge bases in description logics using the \textbf{S}econd setting}) cho bài toán học khái niệm đối với cơ sở tri thức trong logic mô tả. Thuật toán này sử dụng mô hình của cơ sở tri thức kết hợp với mô phỏng hai chiều trong mô hình đó (để mô hình hóa tính không phân biệt được) và cây quyết định (để phân lớp dữ liệu) cho việc tìm kiếm khái niệm kết quả. Ngoài việc trình bày thuật toán, tính đúng đắn của thuật toán cũng được chứng minh thông qua các bổ đề tương ứng.

%-------------------------------------------------------------------
\section{Phân hoạch miền của diễn dịch trong logic mô tả}

Cho diễn dịch $\mI = \tuple{\Delta^\mI, \cdot^\mI}$ trong ngôn ngữ $\mLSP$. Ý tưởng cơ bản của việc làm mịn phân hoạch miền $\Delta^\mI$ của diễn dịch $\mI$ là dựa trên phương pháp học khái niệm sử dụng mô phỏng hai chiều đã được Nguyen và Sza{\l}as đề xuất trong~\cite{Nguyen2013}. Cụ thể là, bắt đầu từ phân hoạch $\{\Delta^\mI\}$, chúng ta thực hiện làm mịn liên tục $\{\Delta^\mI\}$ để đạt được phân hoạch tương ứng với quan hệ $\simSdPdI$ với các kỹ thuật cụ thể đặt ra như sau:
\begin{itemize}
	\item Quá trình làm mịn có thể dừng lại khi một số điều kiện đặt ra được thỏa mãn.		
	\item Trong quá trình làm mịn phân hoạch $\{\Delta^\mI\}$, các khối được tạo ra ở tất cả các bước được ký hiệu là $Y_1, Y_2, \ldots, Y_n$. Để thực hiện được điều này, khi mỗi khối được tạo ra, chúng ta sử dụng một chỉ số mới gán cho khối đó bằng cách tăng giá trị của~$n$. Ta gọi phân hoạch hiện thời là $\mbY = \{Y_{i_1}, Y_{i_2}, \ldots, Y_{i_k}\} \subseteq \{Y_1, Y_2, \ldots, Y_n\}$. Như vậy, $\mbY$ là một tập con của các khối được tạo ra ở trên. Chúng ta thiết lập thông tin nhằm ghi nhận lại khái niệm $C_i$ đặc trưng cho khối $Y_i$ sao cho $C_i^\mI = Y_i$.
	\item Chúng ta có thể sử dụng các chiến lược khác nhau cũng như các hàm tính điểm để tối ưu hóa quá trình làm mịn.
\end{itemize}

\subsection{Bộ chọn cơ bản}
\label{sec:Chap3.BasicSelectors}
Trong mục này, chúng tôi giới thiệu về các bộ chọn cơ bản trong $\mLSPD$ được sử dụng để phân chia khối $Y_{i_j}$, trình bày và chứng minh một định lý về các bộ chọn cơ bản~\cite{Tran2012}. Theo đó, các bộ chọn cơ bản là điều kiện đủ để khi làm mịn liên tục phân hoạch $\{\Delta^\mI\}$ chúng ta đạt được phân hoạch tương ứng với quan hệ tương đương~$\sim_\SdPdI$.
%

\begin{Definition}[Bộ chọn cơ bản]
	\label{def:BasicSelectors}
	Một {\em bộ chọn cơ bản} trong $\mLSPD$ dùng để phân chia khối~$Y_{i_j}$ của phân hoạch $\mbY = \{Y_{i_1}, Y_{i_2}, \ldots, Y_{i_k}\}$ là một khái niệm thuộc một trong các dạng~sau:
	\begin{itemize}
		\item $A$, trong đó $A \in \SigmaDagC$,
%		
		\item $A=d$, trong đó $A \in \SigmaDagA\setminus\SigmaDagC$ và $d \in \Range(A)$,
%		
		\item $\E \sigma.\{d\}$, trong đó $\sigma \in \SigmaDagDR$ và $d \in \Range(\sigma)$,
%
		\item $\E r.C_{i_t}$, trong đó $r \in \SigmaDagOR$ và $1 \leq t \leq k$,
%		
		\item $\E r^-.C_{i_t}$, nếu $\mI \in \Phi^\dag$, $r \in \SigmaDagOR$ và $1 \leq t \leq k$,
%
		\item $\{a\}$, nếu $\mO \in \Phi^\dag$ và $a \in \SigmaDagI$,
%		
		\item $\leq\!1\,r$, nếu $\mF \in \Phi^\dag$ và $r \in \SigmaDagOR$,
%		
		\item $\leq\!1\,r^-$, nếu $\{\mF, \mI\} \subseteq \Phi^\dag$ và $r \in \SigmaDagOR$,
%
		\item $\geq\!l\,r$ và $\leq\!m\,r$, nếu $\mN \in \Phi^\dag$, $r \in \SigmaDagOR$, $0 < l \leq \#\Delta^\mI$ và $0 \leq m < \#\Delta^\mI$,
%
		\item $\geq\!l\,r^-$ và $\leq\!m\,r^-$, nếu $\{\mN, \mI\}\!\subseteq \Phi^\dag$, $r\!\in\!\SigmaDagOR$, $0 <\!l \leq\! \#\Delta^\mI$ và $0 \leq m < \#\Delta^\mI$,
%
		\item $\geq\!l\,r.C_{i_t}$ và $\leq\!m\,r.C_{i_t}$, nếu $\mQ \in \Phi^\dag$, $r \in \SigmaDagOR$, $1 \leq t \leq k$, $0 < l \leq \#C_{i_t}^\mI$ và $0 \leq m < \#C_{i_t}^\mI$,
%
		\item $\geq\!l\,r^-.C_{i_t}$ và $\leq\!m\,r^-.C_{i_t}$, nếu $\{\mQ, \mI\} \subseteq \Phi^\dag$, $r \in \SigmaDagOR$, $1 \leq t \leq k$, $0 < l \leq \#C_{i_t}^\mI$ và $0 \leq m < \#C_{i_t}^\mI$,
%
		\item $\E r.\Self$, nếu $\Self \in \Phi^\dag$ và $r \in \SigmaDagOR$.\myend
	\end{itemize}
\end{Definition}

\begin{Theorem}[Về bộ chọn cơ bản]
\label{th:BasicSelectors}
	Cho $\Sigma$ và $\SigmaDag$ là các bộ ký tự logic mô tả sao cho $\SigmaDag \subseteq \Sigma$, $\Phi$ và $\PhiDag$ là tập các đặc trưng logic mô tả sao cho $\PhiDag \subseteq \Phi$, $\mI$ là một diễn dịch hữu hạn trong $\mLSP$.
	Xuất phát từ phân hoạch $\{\Delta^\mI\}$ và thực hiện việc làm mịn liên tục nó bằng các bộ chọn cơ bản ta sẽ nhận được một phân hoạch tương ứng với quan hệ tương đương~$\sim_\SdPdI$.\myend
\end{Theorem}

\begin{proof}
	Gọi $\mathbb{Y} = \{Y_{i_1}, Y_{i_2}, \ldots ,Y_{i_k}\}$ là phân hoạch cuối cùng đạt được bằng cách làm mịn liên tục phân hoạch $\{\Delta^\mI\}$ thông qua việc sử dụng các bộ chọn cơ bản. Gọi $Z$ là quan hệ tương đương tương ứng với phân hoạch $\mathbb{Y}$ và được định nghĩa là $Z = \{\tuple{x,x'} \mid x,x' \in Y_{i_j}$ với $1 \leq j \leq k\}$. Chú ý rằng $C_{i_j}$ là khái niệm đại diện cho khối~$Y_{i_j}$, nghĩa là $C_{i_j}^\mI = Y_{i_j}$.
	
	Đầu tiên chúng ta chứng minh quan hệ $Z$ là một $\mLSPD$-tự mô phỏng hai chiều của~$\mI$. Giả sử $\SigmaDag \subseteq \Sigma$, $\PhiDag \subseteq \Phi$, $a \in \SigmaDagI$, $A \in \SigmaDagC$, $B \in \SigmaDagA\setminus\SigmaDagC$, $r \in \SigmaDagOR$, $\sigma \in \SigmaDagDR$, $d \in \Range(\sigma)$ và $x,y,x',y' \in \Delta^{\mI}$.
	
	\semiItem{}Xét điều kiện~\eqref{bs:eqA}, ta có $Z(a^\mI, a^\mI)$ luôn thỏa mãn với mọi $a \in \SigmaDagI$.
	
	\semiItem{}Xét điều kiện~\eqref{bs:eqB1} và giả sử $Z(x,x')$ thỏa mãn. Lúc đó tồn tại $1 \leq j \leq k$ sao cho $x, x' \in Y_{i_j}$.
	Vì phân hoạch $\mathbb{Y}$ không thể làm mịn hơn nữa bằng cách sử dụng khái niệm $A$ nên ta có hoặc $Y_{i_j} \subseteq A^\mI$ hoặc $Y_{i_j} \cap A^\mI = \emptyset$.
	Nếu $Y_{i_j} \subseteq A^\mI$ thì $x, x' \in A^\mI$.
	Nếu $Y_{i_j} \cap A^\mI = \emptyset$ thì $x, x' \notin A^\mI$. Do đó, $A^\mI(x) \Leftrightarrow A^\mI(x')$.
	
	\semiItem Xét điều kiện~\eqref{bs:eqB2} và giả sử $Z(x,x')$ thỏa mãn. Tương tự như trên, vì phân hoạch $\mbY$ không thể làm mịn hơn nữa bằng cách sử dụng bộ chọn $(B=d)$ với $d \in \Range(B)$, ta có $Y_{i_j} \subseteq (B=d)^\mI$ hoặc $Y_{i_j} \cap (B=d)^\mI = \emptyset$ với mọi $1 \leq j \leq k$. Nếu $x, x' \in Y_{i_j}$ và $Y_{i_j} \subseteq (B=d)^\mI$ với $d \in \Range(B)$ thì $x, x' \in (B=d)^\mI$, và do đó $B(x) = d = B(x')$. Nếu $x, x' \in Y_{i_j}$ và $Y_{i_j} \cap (B=d)^\mI = \emptyset$ với $d \in \Range(B)$ thì cả $B(x)$ và $B(x')$ không xác định.
	
	\semiItem{}Xét điều kiện~\eqref{bs:eqC1} và giả sử $Z(x,x')$ và $r^\mI(x,y)$ thỏa mãn. Gọi $Y_{i_j} \in \mathbb{Y}$ là khối có chứa~$y$, ta có $x \in (\E r.C_{i_j})^\mI$. Vì $\mathbb{Y}$ không thể làm mịn hơn nữa bằng cách sử dụng $(\E r.C_{i_j})$ nên $x' \in (\E r.C_{i_j})^\mI$. Vì vậy, tồn tại $y' \in \Delta^\mI$ sao cho $r^\mI(x',y')$ thỏa mãn và $y' \in C_{i_j}^\mI = Y_{i_j}$, nghĩa là $Z(y,y')$ thỏa mãn.
	
	\semiItem{}Điều kiện~\eqref{bs:eqC2} được chứng minh tương tự điều kiện~\eqref{bs:eqC1}.
	
	\semiItem{}Xét điều kiện~\eqref{bs:eqD} và giả sử $Z(x,x')$ thỏa mãn. Bằng cách thay khái niệm $A$ trong điều kiện~\eqref{bs:eqB1} bởi khái niệm $\E \sigma.\{d\}$, ta suy ra được $x \in (\E \sigma.\{d\})^\mI$ nếu và chỉ nếu $x' \in (\E \sigma.\{d\})^{\mI'}$. Vì vậy, $\sigma^\mI(x,d) \Leftrightarrow \sigma^{\mI'}(x',d)$.
	
	\semiItem{}Điều kiện~\eqref{bs:eqI1}, \eqref{bs:eqI2} trong trường hợp $\mI \in \Phi^\dag$ được chứng minh tương tự điều kiện~\eqref{bs:eqC1} và~\eqref{bs:eqC2} bằng cách thay vai trò $r$ bởi vai trò $r^-$.
	
	\semiItem{}Điều kiện~\eqref{bs:eqO0} trong trường hợp $\mO \in \Phi^\dag$ được chứng minh tương tự điều kiện~\eqref{bs:eqB1} bằng cách thay khái niệm $A$ bởi khái niệm~$\{a\}$.
	
	\semiItem{}Xét điều kiện~\eqref{bs:eqN} trong trường hợp $\mN \in \Phi^\dag$ và giả sử $Z(x,x')$ thỏa mãn. Đặt $l = \# \{y \mid r^\mI(x,y)\}$. Vì phân hoạch $\mathbb{Y}$ không thể làm mịn hơn nữa bằng cách sử dụng khái niệm $\geq\!l\,r$ (khi $l > 0$) và $\leq\!l\,r$ (khi $l < \# \Delta^\mI$), ta có $x' \in (\geq\!l\,r)^\mI$ và $x' \in (\leq\!l\,r)^\mI$. Từ đó suy ra $\# \{y' \mid r^\mI(x',y')\} = l$.
	
	\semiItem{}Điều kiện~\eqref{bs:eqNI} trong trường hợp $\{\mN, \mI\} \subseteq \Phi^\dag$ được chứng minh tương tự điều kiện~\eqref{bs:eqN} bằng cách thay vai trò $r$ bởi vai trò~$r^-$.
	
	\semiItem{}Xét điều kiện~\eqref{bs:eqF} trong trường hợp $\mF \in \Phi^\dag$ và giả sử $Z(x,x')$ thỏa mãn. Bằng cách thay khái niệm $A$ trong điều kiện~\eqref{bs:eqB1} bởi khái niệm $(\leq\!1\,r)$, ta suy ra được $x \in (\leq\!1\,r)^\mI$ nếu và chỉ nếu $x' \in (\leq\!1\,r)^\mI$. Vì vậy, $[\#\{y \mid r^\mI(x,y)\} \leq 1] \Leftrightarrow [\#\{y' \mid r^\mI(x',y')\} \leq 1]$.
	
	\semiItem{}Điều kiện~\eqref{bs:eqFI} với $\{\mF, \mI\} \subseteq \Phi^\dag$ được chứng minh tương tự điều kiện~\eqref{bs:eqF} bằng cách thay thế vai trò $r$ bởi vai trò~$r^-$.
	
	\semiItem{}Xét điều kiện~\eqref{bs:eqQ} trong trường hợp $\mQ \in \Phi^\dag$ và giả sử $Z(x,x')$ thỏa mãn. Gọi $S = \{y \in \Delta^\mI \mid r^\mI(x,y)\}$ và $S' = \{y' \in \Delta^\mI \mid r^\mI(x',y')\}$. Rõ ràng $S$ và $S'$ hữu hạn. Ta sẽ chứng minh theo phương pháp phản chứng. Giả sử không tồn tại bất kỳ một song ánh $h:S \to S'$ nào sao cho $h \subseteq Z$. Do đó, tồn tại $1 \leq j \leq k$ thỏa $\#(S\cap Y_{i_j}) = l \neq m = \# (S' \cap Y_{i_j})$. Nếu $l > m$ thì $x \in (\geq\!l\,r.C_{i_j})^\mI$ nhưng $x' \notin (\geq\!l\,r.C_{i_j})^\mI$. Nếu $m > l$ thì $x \notin (\geq\!m\,r.C_{i_j})^\mI$ nhưng $x' \in (\geq\!m\,r.C_{i_j})^\mI$. Vì vậy, $x$ và $x'$ sẽ phân biệt nhau bởi một bộ chọn nào đó của $\mLSPD$. Điều này mâu thuẫn với giả thiết là phân hoạch $\mathbb{Y}$ không thể làm mịn hơn được nữa.
	
	\semiItem{}Điều kiện~\eqref{bs:eqQI} trong trường hợp $\{\mQ, \mI\} \subseteq \Phi^\dag$ được chứng minh tương tự điều kiện~\eqref{bs:eqQ} bằng cách thay thế vai trò $r$ bởi vai trò~$r^-$.
	
	\semiItem{}Điều kiện~\eqref{bs:eqU1} thỏa mãn vì với bất kỳ $x\in\Delta^\mI$ ta chỉ cần chọn $x' = x$. Lúc đó, ta có $Z(x, x')$ thỏa mãn.
	
	\semiItem{}Điều kiện~\eqref{bs:eqU2} thỏa mãn vì với bất kỳ $x'\in\Delta^\mI$ ta chỉ cần chọn $x = x'$. Lúc đó, ta có $Z(x, x')$ thỏa mãn.
	
	\semiItem{}Điều kiện~\eqref{bs:eqSelf} trong trường hợp $\Self \in \Phi^\dag$ ta có thể chứng minh tương tự như điều kiện~\eqref{bs:eqB1} bằng cách thay khái niệm $A$ bởi khái niệm~$\E r.\Self$.
	
	Bây giờ chúng ta chứng minh $Z$ là một $\mLSPD$-tự mô phỏng hai chiều lớn nhất của~$\mI$.
%
	Ta thấy, tại mỗi bước làm mịn, quan hệ tương đương tương ứng với phân hoạch đó là một tập cha của $\equiv_\SdPdI$ vì mỗi khối của phân hoạch được đặc trưng bởi một khái niệm. Do đó, với phân hoạch cuối cùng, ta có $Z \supseteq\ \equiv_\SdPdI$.
	%
	Vì $Z$ là một $\mLSPD$-tự mô phỏng hai chiều của $\mI$ và $\sim_\SdPdI$ là một $\mLSPD$-tự mô phỏng hai chiều lớn nhất của $\mI$ nên ta có $Z \subseteq\ \sim_\SdPdI$. Theo Định lý~\ref{th:Consistent}, ta có $\equiv_\SdPdI$ và $\sim_\SdPdI$ trùng nhau. Vậy $Z =\ \sim_\SdPdI$, nghĩa là $Z$ là một $\mLSPD$-tự mô phỏng hai chiều lớn nhất của $\mI$.
\end{proof}

Trong thực tế, để quá trình phân hoạch đạt hiệu quả cao cũng như để phù hợp với việc sử dụng các thuộc tính như là các thành phần cơ bản của ngôn ngữ và tận dụng được các bộ chọn đã tạo ra trong quá trình làm mịn phân hoạch, chúng ta có thể xem xét sử dụng các bộ chọn được trình bày trong Hình~\ref{fig:OtherSelectors}.

\begin{figure}[h!]
\ramka{
	\vspace{-2.0ex}
	\begin{itemize}
		\item $A < d$, $A \leq d$, trong đó $A \in \SigmaDagNA$, $d \in \Range(A)$ và $d$ không phải là giá trị nhỏ nhất của~$\Range(A)$,
	%
		\item $A > d$, $A \geq d$, trong đó $A \in \SigmaDagNA$, $d \in \Range(A)$ và $d$ không phải là giá trị lớn nhất của~$\Range(A)$,
	%
		\item $\E r.\top$, $\E r.C_i$ và $\V r.C_i$, trong đó $r \in \SigmaDagOR$ và $1 \leq i \leq n$,
	%		
		\item $\E r^-.\top$, $\E r^-.C_i$ và $\V r^-.C_i$, nếu $\mI \in \Phi^\dag$, $r \in \SigmaDagOR$ và $1 \leq i \leq n$,
	%
		\item $\geq\!l\,r.C_i$ và $\leq\!m\,r.C_i$, nếu $\mQ \in \Phi^\dag$, $r \in \SigmaDagOR$, $1 \leq i \leq n$, $0 < l \leq \#C_i^\mI$ và $0 \leq m < \#C_i^\mI$,
	%
		\item $\geq\!l\,r^-.C_i$ và $\leq\!m\,r^-.C_i$, nếu $\{\mQ, \mI\} \subseteq \Phi^\dag$, $r \in \SigmaDagOR$, $1 \leq i \leq n$, $0 < l \leq \#C_i^\mI$ và $0 \leq m < \#C_i^\mI$.
	\end{itemize}
	\vspace{-2.0ex}
}
\caption{Các bộ chọn được sử dụng thêm trong thực tế\label{fig:OtherSelectors}}
\end{figure}

\subsection{Các độ đo dựa trên entropy trong việc phân hoạch miền}
\label{sec:Chap3.InfoGain}
Trong ngữ cảnh logic mô tả và phân hoạch miền của diễn dịch trong logic mô tả, entropy được xác định thông qua các khối của phân hoạch. Cho diễn dịch $\mI$ là một hệ thống thông tin, $X$ và $Y$ là các tập con của $\Delta^\mI$, trong đó $X$ đóng vai trò là tập các mẫu dương của khái niệm cần học, $Y$ đóng vai trò là một khối của phân hoạch.
%
\begin{Definition}
	{\em Entropy} của tập $Y$ đối với tập~$X$ trong miền $\Delta^\mI$ của diễn dịch~$\mI$, ký hiệu là $E_{\Delta^\mI}(Y/X)$, được xác định như sau:
	\begin{equation}
		E_{\Delta^\mI}(Y/X)=
		\begin{cases}
			0, \text{ nếu } Y \cap X = \emptyset \text{ hoặc } Y \subseteq X\\
			\displaystyle - \frac{\sharp XY}{\sharp Y}\log_2\frac{\sharp XY}{\sharp Y}-\frac{\sharp \overline{X}Y}{\sharp Y}\log_2\frac{\sharp \overline{X}Y}{\sharp Y}, \textnormal{nếu ngược lại,} \label{eq:Entropy}
		\end{cases}
	\end{equation}
	trong đó $XY$ đại diện cho tập $X \cap Y$ và $\overline{X}Y$ đại diện cho tập $\overline{X} \cap Y$.\myend
\end{Definition}

Entropy là một lý thuyết độ đo về tính không chắc chắn trong các hệ thống thông tin khi các đối tượng trong hệ thống đó xuất hiện nhiều hơn trong một lớp. Entropy có giá trị nhỏ nhất là 0 khi và chỉ khi tất cả các đối tượng thuộc về cùng một lớp. Nói cách khác, tập các đối tượng không bị phân chia bởi tập các mẫu dương cũng như tập các mẫu âm.
Entropy đạt giá trị lớn nhất khi các đối tượng phân bố đều nhau trong các lớp.

\begin{Remark}
	Theo phương trình~\eqref{eq:Entropy}, chúng ta thấy rằng $E_{\Delta^\mI}(Y/X) = 0$ khi và chỉ khi tập $Y$ không bị phân chia bởi tập $X$.\myend
\end{Remark}

Chúng ta cần xác định thuộc tính nào trong hệ thống thông tin huấn luyện để phân chia tập các đối tượng thành các lớp cần học là tốt nhất. Quinlan đề xuất sử dụng gia lượng thông tin ({\em information gain}) nhằm quyết định thứ tự của các thuộc tính cần dùng để phân chia các nút trong cây quyết định~\cite{Quinlan1986}. Trong ngữ cảnh logic mô tả, chúng tôi đưa ra định nghĩa về gia lượng thông tin khi sử dụng một bộ chọn để chia một khối trong phân hoạch.

\begin{Definition}
	{\em Gia lượng thông tin} của bộ chọn $D$ trong việc chia tập $Y$ đối với tập~$X$ trong $\Delta^\mI$ của diễn dịch $\mI$, ký hiệu là $IG_{\Delta^\mI}(Y/X, D)$, được xác định như sau:
	\begin{equation}
		IG_{\Delta^\mI}(Y/X, D) = E_{\Delta^\mI}(Y/X)-
		\left(\!\!\frac{\sharp D^\mI Y}{\sharp Y}E_{\Delta^\mI}(D^\mI Y/X)+\frac{\sharp \overline{D^\mI}Y}{\sharp Y}E_{\Delta^\mI}(\overline{D^\mI}Y/X)\!\!\right)  \label{eq:InfoGain}
	\end{equation}
	trong đó $D^\mI Y$ đại diện cho tập $D^\mI \cap Y$ và $\overline{D^\mI}Y$ đại diện cho tập $\overline{D^\mI} \cap Y$.\myend
\end{Definition}

Gia lượng thông tin dựa trên mức độ giảm bớt thông tin sau khi hệ thống thông tin bị phân chia trên một khối bởi một bộ chọn. Do vậy, chúng ta cần tìm khối và bộ chọn hợp lý sao cho gia lượng thông tin thu được khi sử dụng bộ chọn này để phân chia khối đã chọn là lớn nhất để xây dựng được cây quyết định tốt nhất.

Trong ngữ cảnh $\Delta^\mI$ và $X$ đã rõ ràng, chúng ta viết $E(Y)$ thay cho $E_{\Delta^\mI}(Y/X)$ và $IG(Y, D)$ thay cho $IG_{\Delta^\mI}(Y/X, D)$.

Độ đo gia lượng thông tin chỉ cho phép chúng ta xem xét các bộ chọn đang có ở thời điểm hiện tại. Chúng ta chọn khối cũng như bộ chọn để phân chia sao cho gia lượng thông tin đạt được là lớn nhất trong tất cả các khối và bộ chọn đang có. Vấn đề này dẫn đến nhược điểm là quá trình phân chia này đem lại kết quả tốt ở thời điểm hiện tại nhưng nó có thể không mang lại kết quả tốt cho việc phân chia ở các bước tiếp theo. Để khắc phục nhược điểm này, chúng tôi xây dựng một độ đo mới, gọi là {\em độ đo gia lượng thông tin độ sâu bậc nhất}, nhằm cho phép lựa chọn khối cũng như bộ chọn để phân chia trước theo chiều sâu. Quá trình này cũng giống như việc tìm kiếm các bước đi trong một trò chơi với độ sâu cho trước.

Với mỗi khối $Y_{i_j} \in \mbY$ $(1 \leq j \leq k)$, chúng ta xem xét tất cả các bộ chọn có thể dùng để phân chia $Y_{i_j}$. Giả sử $D_{u} \in \mbD$ là bộ chọn được sử dụng để phân chia khối $Y_{i_j}$, chúng ta nhận được phân hoạch mới $\mbY = \mbY \cup \{Y_s, Y_t\} \setminus \{Y_{i_j}\}$ và tập các bộ chọn mới $\mbD^u_{i_j} = \mbD \cup \{D^u_{{i_j},1}, D^u_{{i_j},2}, \ldots, D^u_{{i_j},m^u_{i_j}}\}$, trong đó $m^u_{i_j}$ là số lượng các bộ chọn mới và $D^u_{{i_j},l}$ $(1 \leq l \leq m^u_{i_j})$ là bộ chọn mới được tạo ra bằng cách sử dụng các luật trong Định nghĩa~\ref{def:BasicSelectors} và Hình~\ref{fig:OtherSelectors}.

\begin{Definition}
	{\em Độ đo gia lượng thông tin độ sâu bậc nhất} của bộ chọn $D_u$ trong việc phân chia khối $Y_{i_j}$, ký hiệu là $fdIG(Y_{i_j}, D_u)$, được xác định như sau:
	{\small
		\begin{equation}
		\!\!\!fdIG(Y_{i_j}, D_u)\!\!=\!\!IG(Y_{i_j}, D_u)+\!
		\!\sum\limits_{v=1\atop v \not= j}^{k}\!\max\limits_{D \in \mbD^u_{i_j}}\!\{\!IG(Y_{i_v},D)\!\}
		+\!\max\limits_{D \in \mbD^u_{i_j}}\!\{\!IG(Y_{s}, D)\!\}+\!\max\limits_{D \in \mbD^u_{i_j}}\!\{\!IG(Y_{t}, D)\!\}.\,\myend\!\!\!
		\end{equation}
	}
	\label{eq:fdIG}
\end{Definition}
\vspace{-4.0ex}

So với độ đo gia lượng thông tin, độ đo gia lượng thông tin bậc nhất tốt hơn bởi vì nó cho phép chúng ta tìm được bộ chọn hợp lý từ những bộ chọn mới phát sinh sau khi thực hiện phân chia một khối.

\subsection{Phân hoạch miền của diễn dịch}

Ta nói rằng tập $Y \subseteq \Delta^\mI$ bị {\em phân chia} bởi $E$ nếu tồn tại $a \in E^+$ và $b \in E^-$ sao cho $\{a^\mI, b^\mI\} \subseteq Y$. Một phân hoạch $\mbY = \{Y_1, Y_2, \ldots, Y_n\}$ của $\Delta^\mI$ được gọi là {\em nhất quán} với~$E$ nếu với mọi $1 \leq i \leq n$, $Y_i$ không bị phân chia bởi $E$.

Cho diễn dịch $\mI$ là một hệ thống thông tin huấn luyện trong $\mLSP$. Gọi $A_d \in \SigmaC$ là một khái niệm đại diện cho ``thuộc tính quyết định'', $E = \tuple{E^+, E^-}$ với $E^+ = \{a \mid a^\mI \in A_d^\mI\}$ và $E^- = \{a \mid a^\mI \in (\neg A_d^\mI)\}$ tương ứng là tập các mẫu dương và mẫu âm của $A_d$ trong~$\mI$. Giả sử rằng $A_d$ có thể được biểu diễn bởi một khái niệm $C$ trong ngôn ngữ con $\mLSPD$, trong đó $\SigmaDag \subseteq \Sigma \setminus \{A_d\}$ và $\PhiDag \subseteq \Phi$. Vấn đề đặt ra là phân hoạch miền $\Delta^\mI$ của diễn dịch $\mI$ sử dụng các khái niệm của $\mLSPD$ để thu được phân hoạch $\mbY$ sao cho $\mbY$ nhất quán với $E$.

Ta thấy rằng, nếu $A_d$ xác định được trong $\mLSPD$ bởi một khái niệm $C$, lúc đó:
\begin{itemize}
	\item theo khẳng định thứ nhất của Định lý~\ref{th:Consistent}, $C^\mI$ phải là hợp của một số lớp tương đương trong phân hoạch $\mbY$ của $\Delta^\mI$ được phân hoạch thông qua $\simSdPdI$,
	
	\item $a^\mI \in C^\mI$ với mọi $a \in E^+$ và $a^\mI \notin C^\mI$ với mọi $a \in E^-$, nghĩa là phân hoạch $\mbY$ nhất quán với $E$.
\end{itemize}

\begin{algorithm}[t]	
	\KwIn{$\mI$, $\SigmaDag$, $\PhiDag$, $E = \tuple{E^-, E^+}$}
	\KwOut{$\mbY = \{Y_{i_1}, Y_{i_2}, \ldots, Y_{i_k}\}$ sao cho $\mbY$ nhất quán với $E$}
	\SetKwFunction{Partition}{Partition}
	
	\BlankLine
	$n:=1$; $Y_1 := \Delta^\mI$; $\mbY := \{Y_1\}$; $C_1 := \top$; $\mbD := \emptyset$\;
	Tạo và thêm các bộ chọn vào $\mbD$\label{step:CreateSelector1}
	\tcc*[r]{\footnotesize theo Định nghĩa~\ref{def:BasicSelectors} và Hình~\ref{fig:OtherSelectors}}
	\While {$(\mbY$ không nhất quán với $E)$ \textnormal{and} $(\mbY$ có thể phân hoạch$)$}
	{
		Chọn bộ chọn $D_u$ trong $\mbD$ và khối $Y_{i_j}$ trong $\mbY$ sao cho $D_u$ chia $Y_{i_j}$ thành hai khối không rỗng\label{step:ChooseBlock}\;
		$s:=n+1$; $t:=n+2$; $n:=n+2$\;
		$Y_s := Y_{i_j} \cap D_u^\mI$;\qquad\quad\!$C_s := C_{i_j} \mand D_u$\;
		$Y_t := Y_{i_j} \cap (\neg D_u)^\mI$;\quad $C_t := C_{i_j} \mand \neg D_u$\;
		$\mbY := \mbY \cup \{Y_s, Y_t\} \setminus \{Y_{i_j}\}$\;    
		Tạo và thêm các bộ chọn mới vào $\mbD$\label{step:CreateSelector2}\tcc*[r]{\footnotesize theo Định nghĩa~\ref{def:BasicSelectors} và Hình~\ref{fig:OtherSelectors}}
	}
	\eIf {$(\mbY$ nhất quán với $E)$}
	{
		\Return $\mbY$\;
	}
	{
		\Return failure;
	}
	\caption{\texttt{Partition} - {\em Phân hoạch miền của diễn dịch trong logic mô tả}} \label{alg:Partition}
\end{algorithm}

Dựa trên ý tưởng của phương pháp học khái niệm của Nguyen và Sza{\l}as~\cite{Nguyen2013} và những nhận xét trên, chúng tôi thiết kế Thuật toán~\ref{alg:Partition} để phân hoạch miền của một diễn dịch trong logic mô tả.
Trong thuật toán này, quá trình phân hoạch miền của một diễn dịch sử dụng các bộ chọn cơ bản (theo Định nghĩa~\ref{def:BasicSelectors}) và các bộ chọn khác (theo mô tả trong Hình~\ref{fig:OtherSelectors}) đã đề cập . Tập các bộ chọn hiện thời được ký hiệu là $\mbD = \{D_1, D_2, \ldots, D_h\}$. Thuật toán dừng khi phân hoạch đạt được nhất quán với $E$ (khi đó thuật toán trả về kết quả là phân hoạch cần tìm) hoặc không thể phân hoạch thêm được nữa (khi đó thuật toán trả về kết quả thất bại).

Việc lựa chọn khối để phân hoạch trước và bộ chọn để phân hoạch khối đó trong Bước~\ref{step:ChooseBlock} có ý nghĩa rất quan trọng đối với quá trình làm mịn phân hoạch. 
Nó quyết định đến việc đạt được phân hoạch nhất quán với $E$ nhanh hoặc chậm. 
Vấn đề đặt ra là khối nào nên phân chia trước và sử dụng bộ chọn nào để phân chia khối đó. Đây là một bài toán mở và cần thiết phải sử dụng các kỹ thuật heuristics. Chúng ta có thể áp dụng hàm tính điểm như là một độ đo cho quá trình phân chia, chẳng hạn như các độ đo dựa trên entropy. Ngoài ra, chúng ta cũng phải lưu ý đến tính đơn giản của bộ chọn và khái niệm đặc trưng của các khối cần phân chia. Các kỹ thuật ngẫu nhiên cũng cần thiết cho quá trình làm mịn phân hoạch. Ví dụ, nếu các bộ chọn cho kết quả giống nhau và đều là những kết quả tốt nhất theo hàm tính điểm trong quá trình phân chia một khối, lúc đó chúng ta có thể chọn ngẫu nhiên một trong những bộ chọn đó để phân chia khối. Trong đề tài này, chúng tôi đề xuất sử dụng độ đo gia lượng thông tin và độ đo gia lượng thông tin bậc nhất như đã đề cập trong Mục~\ref{sec:Chap3.InfoGain}.

Đối với độ đo gia lượng thông tin, giả sử chúng ta có phân hoạch hiện thời là $\mbY= \{Y_{i_1}, Y_{i_2}, \ldots, Y_{i_k}\}$ và tập các bộ chọn hiện thời là $\mbD=\{D_1, D_2, \ldots, D_h\}$ (được xây dựng bằng cách sử dụng các luật trong Định nghĩa~\ref{def:BasicSelectors} và Hình~\ref{fig:OtherSelectors}).
%
Với mỗi khối $Y_{i_j} \in \mbY$ (trong đó $1 \leq j \leq k$), gọi $S_{i_j}$ là bộ chọn đơn giản nhất có được từ $\underset{D_u \in \mbD}{\arg \max}\{IG(Y_{i_j}, D_u)\}$. Như vậy, với phân hoạch hiện thời~$\mbY$, nếu $Y_{i_j}$ được lựa chọn để phân chia thì $S_{i_j}$ chính là bộ chọn dùng để phân chia khối $Y_{i_j}$.

Sau khi quyết định bộ chọn dùng để phân chia các khối, chúng ta tiến hành xác định khối cần phân chia trước $Y_{i_j}$ sao cho khi áp dụng bộ chọn $S_{i_j}$ để phân chia khối $Y_{i_j}$ ta nhận được giá trị gia lượng thông tin lớn nhất. Nghĩa là, chúng ta chọn khối $Y_{i_j} \in \underset{Y_{i_j} \in \mbY}{\arg \max}{\{IG(Y_{i_j}, S_{i_j})\}}$ để phân chia trước.
%

Đối với độ đo gia lượng thông tin bậc nhất, chúng ta chọn khối $Y_{i_j} \in \mbY$ cũng như bộ chọn $D_u \in \mbD$ sao cho $fdIG(Y_{i_j}, D_{u})$ lớn nhất để phân chia trước. Trong trường hợp có nhiều khối và bộ chọn có cùng giá trị độ đo gia lượng thông tin lớn nhất, chúng ta có thể chọn khối kết hợp với bộ chọn đơn giản nhất.

Tiếp theo việc phân chia khối, các bộ chọn mới được tạo ra và thêm vào tập các bộ chọn hiện thời. Tập các bộ chọn này tiếp tục được sử dụng để làm mịn phân hoạch~mới.
%

\begin{Example} \label{ex:Partition1}
Xét cơ sở tri thức $\KB$ như đã cho trong Ví dụ~\ref{ex:KnowledgeBase3} và diễn dịch $\mI$ là mô hình của $\KB$ như sau:
\begin{eqnarray*}
\Delta^\mI \!\!\!&=&\!\!\! \{\Pub_1, \Pub_2, \Pub_3, \Pub_4, \Pub_5, \Pub_6\},\qquad\;\;\,
x^\mI = x \textrm{ với } x \in \{\Pub_1, \Pub_2, \Pub_3, \Pub_4, \Pub_5, \Pub_6\}, \\
\Publication^\mI \!\!\!&=&\!\!\! \Delta^\mI,\quad\Awarded^\mI = \{\Pub_1, \Pub_4, \Pub_6\}, \quad\UsefulPub^\mI = \{\Pub_2,\Pub_3,\Pub_4,\Pub_5,\Pub_6\}, \\
\Cites^\mI \!\!\!&=&\!\!\! \{\tuple{\Pub_1, \Pub_2}, \tuple{\Pub_1, \Pub_3}, \tuple{\Pub_1, \Pub_4}, \tuple{\Pub_1, \Pub_6}, \tuple{\Pub_2, \Pub_3}, \tuple{\Pub_2, \Pub_4},\\
           \!\!\!& &\!\!\! \;\;\tuple{\Pub_2, \Pub_5}, \tuple{\Pub_3, \Pub_4}, \tuple{\Pub_3, \Pub_5}, 
\tuple{\Pub_3, \Pub_6}, \tuple{\Pub_4, \Pub_5}, \tuple{\Pub_4, \Pub_6}\,\}, \\
\Citedby^\mI \!\!\!&=&\!\!\! (\Cites^\mI)^{-1},\;\; 
\textrm{hàm từng phần $\PubYear^\mI$ được đặc tả theo từng cá thể.}
\end{eqnarray*}

Cho $E = \tuple{E^+, E^-}$ với $E^+ = \{\Pub_4, \Pub_6\}$ và $E^- = \{\Pub_1, \Pub_2, \Pub_3, \Pub_5\}$, ngôn ngữ con $\mLSPD$, trong đó $\SigmaDag = \{\Awarded, \Citedby\}$ và  $\Phi^\dag = \emptyset$. Các bước làm mịn phân hoạch~$\{\Delta^\mI\}$ của diễn dịch $\mI$ được mô tả như sau:
\begin{enumerate}
	\item $Y_1 := \Delta^\mI$, $C_1 := \top$, $\mbY := \{Y_1\}$
	\item Theo độ đo gia lượng thông tin, bộ chọn tốt nhất để phân chia $Y_1$ là $\Awarded$. Phân chia khối $Y_1$ bởi $\Awarded$ chúng ta thu được:
	\begin{itemize}
		\item $Y_2 := \{\Pub_1, \Pub_4, \Pub_6\}$, $C_2 := \Awarded$
		\item $Y_3 := \{\Pub_2, \Pub_3, \Pub_5\}$, $C_3 := \neg\Awarded$
		\item $\mbY := \{Y_2, Y_3\}$
	\end{itemize}
	\item Theo độ đo gia lượng thông tin, các bộ chọn tốt nhất để phân chia khối $Y_2$ là $\E\Citedby.\top$, $\E\Citedby.C_2$ và $\E\Citedby.C_3$. Tất cả các bộ chọn này đều phân chia $Y_2$ giống nhau. Chúng ta sử dụng bộ chọn đơn giản nhất $\E\Citedby.\top$ để phân chia $Y_2$ và thu được:
	\begin{itemize}
		\item $Y_4 := \{\Pub_4, \Pub_6\}$, $C_4 := C_2 \mand \E\Citedby.\top$
		\item $Y_5 := \{\Pub_1\}$, $C_5 := C_2 \mand \neg\E\Citedby.\top$
		\item $\mbY := \{Y_3, Y_4, Y_5\}$
	\end{itemize}
\end{enumerate}

Phân hoạch đạt được là $\mbY = \{Y_3, Y_4, Y_5\}$ nhất quán với $E$, gồm khối $Y_4$ chứa $\Pub_4$, $\Pub_6$ với $\Pub_4, \Pub_6 \in E^+$ và các khối $Y_3$, $Y_5$ không chứa cá thể nào của $E^+$ nên ta có kết quả trả về là \mbox{$\mbY = \{Y_3, Y_4, Y_5\}$}
(phân hoạch này không tương ứng với quan hệ $\sim_\SdPdI$).\myend
\end{Example}

Quá trình làm mịn phân hoạch của Ví dụ~\ref{ex:Partition1} được minh họa thông qua cây quyết định như trong Hình~\ref{fig:DecisionTree1}.

\begin{figure}[h!]
\ramka{
	\vspace{-3.0ex}
	\begin{center}
	\begin{tabular}{c}
		\xymatrix@C=14ex@R=7ex{
		& *+[F]{\{\Pub_1,\Pub_2,\Pub_3,\Pub_4,\Pub_5,\Pub_6\}}
		\ar@{->}_{\Awarded}[d]
		\ar@{->}^{\;\;\neg\Awarded}[dr]
		\\
		& *+[F]{\{\Pub_1,\Pub_4,\Pub_6\}}
		\ar@{->}_{\neg\E\Citedby.\top\;\;}[dl]
		\ar@{->}^{\E\Citedby.\top}[d]
		&
		*+[F]{\{\Pub_2,\Pub_3,\Pub_5\}}
		\\
		*+[F]{\{\Pub_1\}}
		& *+[F]{\{\Pub_4,\Pub_6\}}
		} % \xymatrix
	\end{tabular}
	\end{center}
	\vspace{-2.0ex}
}
\caption{Cây quyết định minh họa quá trình làm mịn phân hoạch của Ví dụ~\ref{ex:Partition1}\label{fig:DecisionTree1}}
\end{figure}

\begin{Example}
\label{ex:Partition2}
Xét mô hình $\mI$ của cơ sở tri thức $\KB$ và $E = \tuple{E^+, E^-}$ như đã cho trong Ví dụ~\ref{ex:Partition1} với ngôn ngữ con $\mLSPD$, trong đó $\SigmaDag = \{\Citedby$, $\PubYear\}$ và $\Phi^\dag = \{\mN,\mQ\}$. Các bước làm mịn phân hoạch $\{\Delta^\mI\}$ của $\mI$ được mô tả như sau:
\begin{enumerate}
	\item $Y_1 := \Delta^\mI$, $C_1 := \top$, $\mbY := \{Y_1\}$
	%
	\item Theo độ đo gia lượng thông tin, các bộ chọn tốt nhất để phân chia khối $Y_1$ là \mbox{$\PubYear \geq 2008$} (tương đương với \mbox{$\PubYear > 2007$}) và \mbox{$\geq 3\,\Citedby.\top$} (tương đương với \mbox{$\geq 3\,\Citedby.C_1$}). Ở đây, chúng ta chọn \mbox{$\PubYear \geq 2008$} là bộ chọn đơn giản nhất để phân chia $Y_1$ và thu được:
	\begin{itemize}
		\item $Y_2 := \{\Pub_1, \Pub_2, \Pub_3\}$, $C_2 := (\PubYear \geq 2008)$
		\item $Y_3 := \{\Pub_4, \Pub_5, \Pub_6\}$, $C_3 := (\PubYear < 2008)$
		\item $\mbY := \{Y_2, Y_3\}$
	\end{itemize}
	
	\item  Theo độ đo gia lượng thông tin chúng ta tiếp tục phân chia $Y_3$ bằng bộ chọn $\PubYear \geq 2007$ và thu được:\footnote{Khối $Y_2$ nhất quán với $E$ và khối $Y_3$ không nhất quán với $E$. Một cách tự nhiên, chúng ta chọn khối $Y_3$ để phân chia. Tuy nhiên, nếu chúng ta phân chia $Y_2$ trước bằng bộ chọn $\PubYear \geq 2010$ sẽ cho kết quả tốt hơn về sau này. Đây chính là một gợi ý cho việc xây dựng các heuristic trong quá trình quyết định khối nào nên được phân chia trước và nên sử dụng bộ chọn nào để phân chia khối đó.}
	\begin{itemize}
		\item $Y_4 := \{\Pub_4\}$, $C_4 := C_3 \mand (\PubYear \geq 2007)$
		\item $Y_5 := \{\Pub_5, \Pub_6\}$, $C_5 := C_3 \mand (\PubYear < 2007)$
		\item $\mbY := \{Y_2, Y_4, Y_5\}$
	\end{itemize}
	%
	\item Khối $Y_4$, $Y_5$ không thể tiếp tục phân chia. Vì vậy, mặc dầu $Y_2$ nhất quán với $E$ chúng ta vẫn tiếp tục phân chia nó để sử dụng sau này. Áp dụng độ đo gia lượng thông tin, chúng ta sử dụng bộ chọn $\PubYear \geq 2010$ để phân chia $Y_2$ và thu được:
	\begin{itemize}
		\item $Y_6 := \{\Pub_1\}$, $C_6 := C_2 \mand (\PubYear \geq 2010)$
		\item $Y_7 := \{\Pub_2, \Pub_3\}$, $C_7 := C_2 \mand (\PubYear < 2010)$
		\item $\mbY := \{Y_4, Y_5, Y_6, Y_7\}$
	\end{itemize}
	%
	\item Theo độ đo gia lượng thông tin, chúng ta phân chia khối $Y_5$ bằng bộ chọn $\E\Citedby.C_6$ và thu được:
	\begin{itemize}
		\item $Y_8 := \{\Pub_6\}$, $C_8 := C_5 \mand \E\Citedby.C_6$
		\item $Y_9 := \{\Pub_5\}$, $C_9 := C_5 \mand \neg\E\Citedby.C_6$
		\item $\mbY := \{Y_4, Y_6, Y_7, Y_8, Y_9\}$
	\end{itemize}
\end{enumerate}

Phân hoạch thu được là $\mbY = \{Y_4, Y_6, Y_7, Y_8, Y_9\}$ nhất quán với $E$ gồm khối $Y_4$ chứa $\Pub_4$, khối $Y_8$ chứa $\Pub_6$, với $\Pub_4, \Pub_6 \in E^+$ và các khối $Y_6, Y_7, Y_9$ không chứa cá thể nào của $E^+$ nên ta có kết quả trả về là $\mbY = \{Y_4, Y_6, Y_7, Y_8, Y_9\}$.\myend
\end{Example}

Quá trình làm mịn phân hoạch của Ví dụ~\ref{ex:Partition2} được minh họa thông qua cây quyết định như trong Hình~\ref{fig:DecisionTree2}.

\begin{figure}[h!]
\ramka{
	\vspace{-3.0ex}
	\begin{center}
	\begin{tabular}{c}
		\xymatrix@C=6ex@R=6ex{
			& & *+[F]{\{\Pub_1,\Pub_2,\Pub_3,\Pub_4,\Pub_5,\Pub_6\}}
			\ar@{->}_{\PubYear\geq 2008\ \ }[dl]
			\ar@{->}^{\PubYear<2008}[d] & &
			\\
			& *+[F]{\{\Pub_1,\Pub_2,\Pub_3\}}
			\ar@{->}_{\PubYear\geq2010\ }[dl]
			\ar@{->}^{\PubYear<2010}[d]
			&
			*+[F]{\{\Pub_4,\Pub_5,\Pub_6\}}
			\ar@{->}_{\PubYear\geq2007}[d]
			\ar@{->}^{\ \ \PubYear<2007}[dr] & &
			\\
			*+[F]{\{\Pub_1\}}
			& *+[F]{\{\Pub_2,\Pub_3\}} & *+[F]{\{\Pub_4\}} & *+[F]{\{\Pub_5,\Pub_6\}}
			\ar@{->}_{\E\Citedby.C_6}[d]
			\ar@{->}^{\neg\E\Citedby.C_6}[dr]
			&
			\\
			& & & *+[F]{\{\Pub_6\}}& *+[F]{\{\Pub_5\}}
		} % \xymatrix
	\end{tabular}
	\end{center}
	\vspace{-2.5ex}
}
\caption{Cây quyết định minh họa quá trình làm mịn phân hoạch của Ví dụ~\ref{ex:Partition2}\label{fig:DecisionTree2}}
\end{figure}

Ví dụ sau đây minh họa cho trường hợp làm mịn phân hoạch miền $\{\Delta^\mI\}$ của diễn dịch $\mI$ không sử dụng vai trò, nghĩa là, $\SigmaDagOR \cup \SigmaDagDR = \emptyset$. Do đó, phương pháp đã đề xuất ở trên giống như phương pháp phân hoạch truyền thống trong học máy dựa trên cây quyết định.

\begin{Example}
\label{ex:Partition3}
Xét mô hình $\mI$ của cơ sở tri thức $\KB$ như đã cho trong Ví dụ~\ref{ex:Partition1} và $E = \tuple{E^+, E^-}$ với $E^+ = \{\Pub_4, \Pub_6\}$ và $E^- = \{\Pub_1, \Pub_2, \Pub_3, \Pub_5\}$ trong ngôn ngữ con $\mLSPD$, trong đó $\Sigma^\dag = \{\Awarded,\PubYear\}$ và $\Phi^\dag = \emptyset$. Các bước làm mịn phân hoạch $\{\Delta^\mI\}$ của~$\mI$ được mô tả như sau:
\begin{enumerate}
	\item $Y_1 := \Delta^\mI$, $C_1 := \top$, $\mbY := \{Y_1\}$
	\item Theo độ đo gia lượng thông tin, bộ chọn tốt nhất tại bước này để phân chia khối $Y_1$ là $\Awarded$ và $\PubYear \geq 2008$. Chúng ta chọn $\Awarded$ để phân chia $Y_1$ và thu~được:
	\begin{itemize}
		\item $Y_2 := \{\Pub_1, \Pub_4, \Pub_6\}$, $C_2 := \Awarded$
		\item $Y_3 := \{\Pub_2, \Pub_3, \Pub_5\}$, $C_3 := \neg\Awarded$
		\item $\mbY := \{Y_2, Y_3\}$.
	\end{itemize}
%
	\item Theo độ đo gia lượng thông tin, bộ chọn tốt nhất tại bước này để phân chia khối $Y_2$ là $\PubYear \geq 2009$. Ta chọn $\PubYear \geq 2009$ để phân chia $Y_2$ và thu được:
	\begin{itemize}
		\item $Y_4 := \{\Pub_1\}$, $C_4 := C_2 \mand (\PubYear \geq 2009)$
		\item $Y_5 := \{\Pub_4, \Pub_6\}$, $C_5 := C_2 \mand (\PubYear < 2009)$
		\item $\mbY := \{Y_3, Y_4, Y_5\}$.
	\end{itemize}
\end{enumerate}

\vspace{-1.0ex}
Phân hoạch đạt được là $\mbY = \{Y_3, Y_4, Y_5\}$ nhất quán với $E$, gồm $Y_5$ chứa $\Pub_4$, $\Pub_6$ với $\Pub_4, \Pub_6 \in E^+$ và $Y_3$, $Y_4$ không chứa cá thể nào của $E^+$ nên kết quả trả về là phân hoạch $\mbY = \{Y_3,Y_4,Y_5\}$
(phân hoạch này không tương ứng với quan hệ $\sim_\SdPdI$).\myend
\end{Example}

\vspace{-1.0ex}
Quá trình làm mịn phân hoạch của Ví dụ~\ref{ex:Partition3} được minh họa thông qua cây quyết định như trong Hình~\ref{fig:DecisionTree3}.

\begin{figure}[h!]
	\ramka{
	\vspace{-3.0ex}
	\begin{center}
	\begin{tabular}{c}
		\xymatrix@C=14ex@R=7ex{
			& *+[F]{\{\Pub_1,\Pub_2,\Pub_3,\Pub_4,\Pub_5,\Pub_6\}}
			\ar@{->}_{\Awarded}[d]
			\ar@{->}^{\;\;\neg\Awarded}[dr]
			\\
			& *+[F]{\{\Pub_1,\Pub_4,\Pub_6\}}
			\ar@{->}_{\PubYear \geq 2009\;\;}[dl]
			\ar@{->}^{\PubYear < 2009}[d]
			&
			*+[F]{\{\Pub_2,\Pub_3,\Pub_5\}}
			\\
			*+[F]{\{\Pub_1\}}
			& *+[F]{\{\Pub_4,\Pub_6\}}
			} % \xymatrix
			\end{tabular}
			\end{center}
			\vspace{-2.0ex}
		}
	\caption{Cây quyết định minh họa quá trình làm mịn phân hoạch của Ví dụ~\ref{ex:Partition3}\label{fig:DecisionTree3}}
\end{figure}

\section{Học khái niệm trong logic mô tả}
\label{sec:Chap3.ConceptLearning}
\subsection{Thuật toán \BBCLearnS}
\label{sec:Chap3.BBCL2}

Như đã đề cập trong Mục~\ref{sec:Chap3.Introduction}, bài toán học khái niệm đối với cơ sở tri thức trong logic mô tả được mô tả như sau: 

Cho cơ sở tri thức $\KB$ trong logic mô tả $L$ và các tập các cá thể $E^+$, $E^-$. Học khái niệm $C$ trong $L$ sao cho:

$\bullet$ $\KB \models C(a)$ với mọi $a \in E^+$, và

$\bullet$ $\KB \not\models C(a)$, với mọi $a \in E^-$,

\noindent
trong đó $E^+$ chứa các mẫu dương và $E^-$ chứa các mẫu âm của khái niệm $C$.

\begin{algorithm}[h!]
	\KwIn{$\KB$, $\SigmaDag$, $\PhiDag$, $E = \tuple{E^+, E^-}$, $K$}
	\KwOut{Khái niệm $C$ sao cho:
		\begin{itemize}
			\item $\KB \models C(a)$ với mọi $a \in E^+$, và
			\item $\KB \not\models C(a)$ for all $a \in E^-$.
		\end{itemize}
	}
	%  \SetSideCommentRight
	\SetKwFunction{PartitionDomain}{Partition}
	\SetKwFunction{Simplify}{Simplify}
	$E_0^- := \emptyset$; $\mbC:=\emptyset$; $\mbC_0:=\emptyset$\;
	\While {\textnormal{not }$($too hard to extend $\mbC)$ \textnormal{and} $(E_0^- \neq E^-)$}
	{ \label{step:BBCL2While1}
		Xây dựng mô hình hữu hạn $\mI$ của $\KB$ hoặc $\mI = \mI_{\mid K}'$\label{step:BBCL2ConstructModel}\;
		$\mbY := $\PartitionDomain($\mI$, $\SigmaDag$, $\PhiDag$, $E$)\label{step:BBCL2Partition}\tcc*[r]{\footnotesize phân hoạch miền của $\mI$}
		\ForEach{$Y_{i_j} \in \mbY$, $\E a \in E^-: a^\mI \in Y_{i_j}$ \textnormal{and} $\V a \in E^+: a^\mI \not\in Y_{i_j}$} 
		{ \label{step:BBCL2ForEach1}
			\eIf {$(\KB \models \neg C_{i_j}(a), \V a \in E^+)$}
			{
				\If {$(\KB \not\models (\bigsqcap\mbC \sqsubseteq \neg C_{i_j}))$}
				{
					$\mbC := \mbC \cup \{\neg C_{i_j}\}$\label{step:BBCL2Add1}\;
					$E_0^- := E_0^- \cup \{a \in E^- \mid a^\mI \in Y_{i_j}\}$\;
				}
			}
			{
				$\mbC_0 := \mbC_0 \cup \{\neg C_{i_j}\}$\;
			}
		}
	}
	\While {\textnormal{not }$($too hard to extend $\mbC)$ \textnormal{and} $(E_0^- \neq E^-)$}
	{ \label{step:BBCL2While2}
		$D:=D_1 \mor D_2 \mor \cdots \mor D_l$, với $D_1, D_2, \ldots, D_l$ được chọn ngẫu nhiên từ $\mbC_0$\;
		\If {$(\KB \models D(a), \V a \in E^+)$}
		{
			\If {$(\KB \not\models (\bigsqcap\mbC) \sqsubseteq D)$ \textnormal{and} $(\E a \in E^-\setminus E_0^-: \KB \not\models (\bigsqcap\mbC)(a))$}
			{
				$\mbC := \mbC \cup \{D\}$\label{step:BBCL2Add2}\;
				$E_0^- := E_0^- \cup \{a \mid a\in E^- \setminus E_0^-, \KB \not\models (\bigsqcap\mbC)(a)\}$\;
			}
		}
	}
	\eIf{$(E_0^- = E^-)$}
	{
		\ForEach{$D \in \mbC$}
		{
			\If{$\KB \not \models \bigsqcap(\mbC \setminus \{D\})(a), \V a \in E^-$}
			{
				$\mbC := \mbC \setminus \{D\}$\label{step:BBCL2Remove}\;
			}
		}
		$C := \bigsqcap\mbC$\label{step:BBCL2Result}\;
		\Return $C_{rs} :=$ \Simplify($C$)\label{step:BBCL2Simplify}\tcc*[r]{\footnotesize rút gọn khái niệm $C$}
	}
	{
		\Return failure\;
	}
	\caption{\texttt{BBCL2} - {\em Học khái niệm đối với cơ sở tri thức trong logic mô tả}\label{alg:BBCL2}}
\end{algorithm}

Ý tưởng chính của thuật toán \BBCLearnS để giải quyết bài toán này là sử dụng các mô hình của $\KB$ kết hợp với mô phỏng hai chiều trong mô hình đó (để mô hình hóa tính không phân biệt được) và cây quyết định (để phân lớp dữ liệu) cho việc tìm kiếm khái niệm $C$. Thuật toán này sử dụng Thuật toán~\ref{alg:Partition} để làm mịn phân hoạch~$\{\Delta^\mI\}$ của diễn dịch $\mI$ (là mô hình của $\KB$) nhằm đạt được phân hoạch nhất quán với $E = \tuple{E^+, E^-}$.

Thuật toán tiến hành xây dựng tập $E^-_0$ và mở rộng nó sao cho $E^-_0$ phủ càng lúc càng nhiều cá thể trong $E^-$, xây tập $\mbC$ gồm các phần tử là các khái niệm $D$ sao cho $\KB \models D(a)$ với mọi $a \in E^+$ và xây dựng tập $\mbC_0$ gồm khái niệm để trợ giúp cho việc xây dựng khái niệm $C$. 
Khi một khái niệm $D$ không thỏa mãn điều kiện $\KB \models \neg D(a)$ với mọi $a \in E^-$ nhưng nó là một khái niệm ứng viên ``tốt'' thì khái niệm $D$ được đưa vào $\mbC_0$. Sau này, khi cần thiết, các khái niệm trong $\mbC_0$ được lấy ra, thực hiện phép hợp và kiểm tra xem nó có thỏa mãn điều kiện để thêm vào $\mbC$ hay không. Như vậy, trong quá trình học chúng ta luôn có:
\begin{itemize}
	\item $\KB \models (\bigsqcap\mbC)(a)$ với mọi $a \in E^+$, và
	\item $\KB \not\models (\bigsqcap\mbC)(a)$ với mọi $a \in E^-_0$. 
\end{itemize}

Thuật toán mở rộng $\mbC$ sao cho $\KB \not\models(\bigsqcap\mbC)(a)$ với càng lúc càng nhiều $a \in E^-$. Như vậy, mở rộng $\mbC$ đồng nghĩa với việc mở rộng $E^-_0$. Khi $E^-_0 = E^-$ thuật toán trả về khái niệm $\bigsqcap\mbC$ sau khi đã thực hiện việc chuẩn hóa và đơn giản hóa.

Điều kiện ``not (\textit{too hard to extend} $\mbC$)'' trong Bước~\ref{step:BBCL2While1} và~\ref{step:BBCL2While2} của thuật toán \BBCLearnS là khác nhau. Điều kiện trong Bước~\ref{step:BBCL2While1} phụ thuộc vào kết quả làm mịn phân hoạch~$\{\Delta^\mI\}$ của diễn dịch $\mI$, trong khi đó điều kiện trong Bước~\ref{step:BBCL2While2} phụ thuộc vào việc chọn ngẫu nhiên các khái niệm từ tập $\mbC_0$. Đây là những điều kiện mở và chúng ta có thể xây dựng các điều kiện này tùy thuộc vào từng yêu cầu cụ thể của bài toán.

Việc xây dựng các diễn dịch $\mI$ là mô hình của $\KB$ ở Bước~\ref{step:BBCL2ConstructModel} có thể được thực hiện bằng các thuật toán tableaux đã được đề xuất cho logic mô tả \ALC~\cite{Nguyen2009}, \ALCI~\cite{Nguyen2011B}, \SH~\cite{Nguyen2010}, \SHI~\cite{Horrocks1999,Nguyen2011C}, \SHIQ~\cite{Horrocks2000B}, \SHOIQ~\cite{Horrocks2007B}, \SROIQ~\cite{Horrocks2006}. Nếu logic $L$ có tính chất mô hình hữu hạn thì các diễn dịch~$\mI$ được xây dựng sao cho $\mI$ là mô hình hữu hạn của $\KB$. Ngược lại, các diễn dịch~$\mI$ được xây dựng sao cho $\mI$ là mô hình hữu hạn của $\KB$ hoặc $\mI = \mI'_{\mid k}$, trong đó $\mI'$ là một mô hình không hữu hạn của $\KB$ và $k$ là một tham số của thuật toán học (chẳng hạn, $k = 5$).

Chúng ta nhận thấy rằng, khi khái niệm $\neg C_{i_j}$ được thêm vào $\mbC$ thì $a^\mI \in (\neg C_{i_j})^\mI$ với mọi $a \in E^+$. Đây là một điều kiện rất tốt để chúng ta có thể hy vọng rằng $\KB \models \neg C_{i_j}(a)$ với mọi $a \in E^+$. Sử dụng các thuật toán tableaux đối với từng logic mô tả cụ thể (thông qua các bộ suy luận), thuật toán \BBCLearn tiến hành kiểm tra xem $\KB \models \neg C_{i_j}(a)$ có thỏa mãn với mọi $a \in E^+$ hay không. Nếu điều này thỏa mãn, $\neg C_{i_j}$ được thêm vào tập $\mbC$. Ngược lại, $\neg C_{i_j}$ được thêm vào tập $\mbC_0$ với hy vọng sau này có thể sử dụng được nó trong quá trình lấy hợp của các khái niệm trong $\mbC_0$. Nghĩa là, một khái niệm $D \in \mbC_0$ không thỏa mãn $\KB \models D(a)$ với mọi $a \in E^+$, nhưng khi lấy hợp của một nhóm các khái niệm $D_1, D_2, \ldots, D_l$ trong $\mbC_0$ thì có thể $\KB \models (D_1 \mor D_2 \mor \ldots \mor D_l)(a)$ với mọi $a \in E^+$.
Do đó, khi quá trình mở rộng $\mbC$ gặp khó khăn bằng cách sử dụng các $C_{i_j}$ (là khái niệm đặc trưng tương ứng của các khối~$Y_{i_j}$ trong phân hoạch $\mbY$ đạt được thông qua việc phân hoạch miền của mô hình~$\KB$), chúng ta có thể chuyển sang lấy hợp của các khái niệm trong $\mbC_0$ để xem xét bổ sung vào tập $\mbC$.

Việc rút gọn khái niệm kết quả trong Bước~\ref{step:BBCL2Simplify} có thể được thưc hiện thông qua việc chuẩn hóa khái niệm, sau đó tiến hành đo độ giống nhau giữa các khái niệm để tiến hành việc gộp các khái niệm theo các luật De~Morgan theo thứ tự ưu tiên từ cao đến thấp.

\subsection{Tính đúng của thuật toán BBCL2}

\begin{Proposition}[Tính đúng đắn của thuật toán \BBCLearnS]
	Thuật toán \BBCLearnS là đúng đắn. Nghĩa là, nếu thuật toán \BBCLearnS trả về một khái niệm $C_{rs}$ thì $C_{rs}$ là một lời giải của bài toán học khái niệm cho cơ sở tri thức trong logic mô tả với ngữ cảnh~(2).\myend
\end{Proposition}

\begin{proof}
	Giả sử $C_{rs}$ là khái niệm kết quả của thuật toán \BBCLearnS và $C$ là khái niệm $\bigsqcap\mbC$ trong bước~\ref{step:BBCL2Result}. Vì $C_{rs}$ thu được từ khái niệm $C$ thông qua phép biến đổi bảo toàn tính tương đương của khái niệm nên chúng ta chỉ cần chứng minh hai khẳng định~sau:
	\begin{itemize}
		\item $\KB \models C(a)$ với mọi $a \in E^+$, và
		\item $\KB \not\models C(a)$ với mọi $a \in E^-$.
	\end{itemize}
	
	Đầu tiên chúng ta chứng minh $\KB \models C(a)$ với mọi $a \in E^+$. Ta thấy rằng tập các khái niệm $\mbC$ chỉ được mở rộng tại các Bước~\ref{step:BBCL2Add1} và~\ref{step:BBCL2Add2}. Một khái niệm $D$ được thêm vào $\mbC$ khi $\KB \models D(a)$ với mọi $a \in E^+$. Đặt $n = \sharp\mbC$ sau khi đã loại bỏ những khái niệm $D$ khỏi $\mbC$ ở bước~\ref{step:BBCL2Remove}. Rõ ràng, ta thấy tập $\mbC$ chỉ chứa những khái niệm $D_i$, $1 \leq i \leq n$, sao cho $\KB \models D_i(a)$ với mọi $a \in E^+$. Do đó, $\KB \models (D_1 \mand D_2 \mand \cdots \mand D_n)(a)$ với mọi $a \in E^+$. 
	Nói cách khác, $\KB \models C(a)$ với mọi $a \in E^+$.
	
	Bây giờ chúng ta chứng minh $\KB \not\models C(a)$ với mọi $a \in E^-$. Ta thấy rằng quá trình mở rộng cũng như thu hẹp tập $\mbC$ tại các Bước~\ref{step:BBCL2Add1}, \ref{step:BBCL2Add2} và \ref{step:BBCL2Remove} luôn đảm bảo được rằng $\KB \not\models C(a)$ với mọi $a \in E^-_0$ (khởi đầu $E^-_0 = \emptyset$). Thật vậy, tại Bước~\ref{step:BBCL2Add1}, thuật toán chỉ xem xét những khái niệm $C_{i_j}$ mà $Y_{i_j}$ chứa các $a^\mI$ với $a \in E^-$ và không chứa $a^\mI$ nào với $a \in E^+$. Rõ ràng, nếu $\KB \models \neg C_{i_j}(a)$ với mọi $a \in E^+$ thì $\KB \not\models \neg C_{i_j}(a)$ với mọi $a \in E^-$ mà $a^\mI \in Y_{i_j}$. Do đó, khi thêm $\neg C_{i_j}$ vào $\mbC$ và thêm tất cả $a \in E^-$ thỏa mãn $a^\mI \in Y_{i_j}$ vào $E^-_0$ ta có $\KB \not\models \bigsqcap\mbC(a)$ với mọi $a \in E^-_0$. Tại Bước~\ref{step:BBCL2Add2} và~\ref{step:BBCL2Remove}, với lập luận tương tự khi thêm các khái niệm vào $\mbC$ và loại bỏ các khái niệm ra khỏi $\mbC$, ta luôn có $\KB \not\models \bigsqcap\mbC(a)$ với mọi $a \in E^-_0$. Khi $E^-_0 = E^-$ ta có $\KB \not\models \bigsqcap\mbC(a)$ với mọi $a \in E^-$. Nói cách khác, $\KB \not\models C(a)$ với mọi $a \in E^-$.
	
	Như vậy ta kết luận rằng nếu thuật toán \BBCLearnS không kết thúc với kết quả thất bại thì khái niệm trả về $C_{rs}$ là một lời giải của bài toán học khái niệm cho cơ sở tri thức trong logic mô tả. 
\end{proof}

\begin{Remark}[Độ phức tạp của thuật toán \BBCLearnS]
Học khái niệm cho cơ sở tri thức trong logic mô tả liên quan chặt chẽ với vấn đề suy luận tự động trong logic mô tả. Đối với vấn đề suy luận tự động, độ phức tạp của bài toán này là \EXPTIME-khó ngay cả đối với logic mô tả cơ bản \ALC. Đến nay, các công trình nghiên cứu vẫn chưa chỉ ra được dấu hiệu nào cho thấy có thể hy vọng làm giảm độ phức tạp của bài toán suy luận. Một cách tổng quát, bài toán 
kiểm tra tính thỏa trong logic mô tả thường là \EXPTIME-đầy đủ.
Thuật toán BBCL2 sử dụng một vòng lặp tuyến tính có giới hạn là lực lượng của $C_0$ cho bài toán suy luận. Do đó, thuật toán này có độ phức tạp là hàm mũ (xét theo kích thước của $\KB$, $E^+$ và $E^-$ với giả thiết là $\SigmaDag$ cố định).\myend
\end{Remark}

\subsection{Ví dụ minh họa}
\begin{Example}
\label{ex:Chap3.ConceptLearning1}
	Xét cơ sở tri thức $\KB_0 = \tuple{\mR,\mT,\mA_0}$ như đã cho trong Ví dụ~\ref{ex:KnowledgeBase3} và $E = \tuple{E^+, E^-}$ đối với $E^+ = \{\Pub_4$, $\Pub_6\}$, $E^- = \{\Pub_1$, $\Pub_2$, $\Pub_3$, $\Pub_5\}$, $\SigmaDag = \{\Awarded$, $\Citedby\}$ và $\Phi^\dag = \emptyset$. Học định nghĩa cho khái niệm $A_d$ với $\KB = \tuple{\mR,\mT,\mA}$, trong đó $\mA = \mA_0 \cup \{A_d(a) \mid a \in E^+\} \cup \{\neg A_d(a) \mid a \in E^-\}$. 
	%
	Thuật toán \BBCLearnS thực hiện các bước như sau: 
	\begin{enumerate}
		\item $\mbC := \emptyset$, $\mbC_0 := \emptyset$, $E^-_0: = \emptyset$.
		\item $\KB$ có nhiều mô hình, trong đó mô hình $\mI$ được đặc tả trong Ví dụ~\ref{ex:Partition1} như sau:
		\[
		\!\!\!\!\!\!\!\!\!\begin{array}{r c l}
		\Delta^\mI &=& \{\Pub_1, \Pub_2, \Pub_3, \Pub_4, \Pub_5, \Pub_6\},\qquad x^\mI = x \textrm{ với } x \in \{\Pub_1, \Pub_2, \Pub_3, \Pub_4, \Pub_5, \Pub_6\}, \\
		\Publication^\mI &=& \Delta^\mI,\;\;\Awarded^\mI = \{\Pub_1, \Pub_4, \Pub_6\}, \;\;\UsefulPub^\mI = \{\Pub_2,\Pub_3,\Pub_4,\Pub_5,\Pub_6\}, \\
		\Cites^\mI &=& \{\tuple{\Pub_1, \Pub_2}, \tuple{\Pub_1, \Pub_3}, \tuple{\Pub_1, \Pub_4}, \tuple{\Pub_1, \Pub_6}, \tuple{\Pub_2, \Pub_3}, \tuple{\Pub_2, \Pub_4},\\
		& & \;\;\tuple{\Pub_2, \Pub_5}, \tuple{\Pub_3, \Pub_4}, \tuple{\Pub_3, \Pub_5}, 
		\tuple{\Pub_3, \Pub_6}, \tuple{\Pub_4, \Pub_5}, \tuple{\Pub_4, \Pub_6}\,\}, \\
		\Citedby^\mI &=& (\Cites^\mI)^{-1},\;\;\textrm{hàm từng phần $\PubYear^\mI$ được đặc tả theo từng cá thể.}
		\end{array}
		\]
		
		\item Áp dụng Thuật toán~\ref{alg:Partition} để làm mịn phân hoạch $\{\Delta^\mI\}$ của $\mI$, chúng ta thu được phân hoạch $\mbY = \{Y_3, Y_4, Y_5\}$ nhất quán với $E$ tương ứng với các khái niệm đặc trưng $C_3, C_4, C_5$, trong đó $Y_3=\{\Pub_2, \Pub_3, \Pub_5\}$, $Y_4 = \{\Pub_4, \Pub_6\}$, $Y_5 = \{\Pub_1\}$ và $C_3 \equiv \neg\Awarded$, $C_4 \equiv \Awarded \mand \E\Citedby.\top$, $C_5 \equiv \neg\Awarded \mand \E\Citedby.\top$. (Xem quá trình phân hoạch ở Ví dụ~\ref{ex:Partition1})

		\item Vì $Y_3 \subseteq E^-$ nên ta tiến hành xem xét đối với $C_3 \equiv \neg\Awarded$. Vì $\KB \models \neg C_3(a)$ với mọi $a \in E^+$ nên ta thêm $\neg C_3$ vào $\mbC$ và thêm các phần tử của $Y_3$ vào $E^-_0$. Do đó, ta có $\mbC = \{C_3\}$ và $E^-_0 = \{\Pub_2,\Pub_3,\Pub_5\}$.
		
		\item Vì $Y_5 \subseteq E^-$ nên ta tiến hành xem xét đối với $C_5 \equiv \Awarded \mand \neg\E\Citedby.\top$. Vì $\KB \models \neg C_5(a)$ với mọi $a \in E^+$ và $\bigsqcap\mbC$ không bị bao hàm bởi $C_5$ dựa trên $\KB$ nên ta thêm $\neg C_5$ vào $\mbC$. Do đó, ta có $\mbC = \{\neg C_3, \neg C_5\}$, $\bigsqcap\mbC \equiv \neg C_3 \mand \neg C_5 \equiv \neg\neg\Awarded \mand \neg (\Awarded \mand \neg\E\Citedby.\top)$ và $E^-_0 = \{\Pub_1,\Pub_2,\Pub_3,\Pub_5\}$.
		
		\item Vì $E^-_0 = E^-$ nên ta có $C \equiv \bigsqcap\mbC \equiv \neg\neg\Awarded \mand \neg(\Awarded \mand \neg \E\Citedby.\top)$. Rút gọn $C$ ta được kết quả trả về là $C_{rs} \equiv \Awarded \mand \E\Citedby.\top$.\myend  
	\end{enumerate}
\end{Example}

\begin{Example}
\label{ex:Chap3.ConceptLearning3}
	Cho $\KB_0$, $E$, $\KB$, $\PhiDag$ như trong Ví dụ~\ref{ex:Chap3.ConceptLearning1} và thay đổi $\SigmaDag = \{\Citedby, \PubYear\}$. Thuật toán \BBCLearnS thực hiện hai bước đầu tiên như Ví dụ~\ref{ex:Chap3.ConceptLearning1} và các bước tiếp theo như sau:	
	\begin{enumerate}
		\setcounter{enumi}{2}
		\item Áp dụng Thuật toán~\ref{alg:Partition} để làm mịn phân hoạch $\{\Delta^\mI\}$ của $\mI$, chúng ta thu được phân hoạch $\mbY = \{Y_4, Y_6, Y_7, Y_8, Y_9\}$ nhất quán với $E$ tương ứng với các khái niệm đặc trưng $C_4, C_6, C_7, C_8, C_9$, trong đó
		$Y_4 = \{\Pub_4\}$,
		$Y_6 = \{\Pub_1\}$,
		$Y_7 = \{\Pub_2, \Pub_3\}$,
		$Y_8 = \{\Pub_6\}$,
		$Y_9 = \{\Pub_5\}$ và
		$C_4 \equiv (\PubYear < 2008) \mand (PubYear \geq 2007)$, 
		$C_6 \equiv (\PubYear \geq 2008) \mand (\PubYear \geq 2010)$, 
		$C_7 \equiv (\PubYear \geq 2008) \mand (\PubYear < 2010)$,
		$C_8\!\equiv\!(\PubYear\!<\!2008) \mand (\PubYear\!<\!2007) \mand \E \Citedby.((\PubYear\!\geq\!2008) \mand (\PubYear\!\geq\!2010))$,
		$C_9\!\equiv\!(\PubYear\!<\!2008) \mand (\PubYear\!<\!2007) \mand\!\neg\E\Citedby.((\PubYear\!\geq\!2008)\!\mand\!(\PubYear\!\geq\!2010))$. (Xem quá trình phân hoạch ở Ví dụ~\ref{ex:Partition2})
		
		\item Vì $Y_6 \subseteq E^-$ nên ta tiến hành xem xét đối với $C_6 \equiv (\PubYear \geq 2008) \mand (\PubYear \geq 2010)$. Vì $\KB \models \neg C_6(a)$ với mọi $a \in E^+$ nên ta thêm $\neg C_6$ vào $\mbC$ và thêm tất cả các phần tử của $Y_6$ vào $E^-_0$. Do đó, ta có $\mbC = \{\neg C_6\}$ và $E_0^- = \{\Pub_1\}$.
		
		\item Vì $Y_7 \subseteq E^-$ nên ta tiến hành xem xét đối với $C_7 \equiv (\PubYear \geq 2008) \mand (\PubYear < 2010)$. Vì $\KB \models \neg C_7(a)$ với mọi $a \in E^+$ và $\bigsqcap\mbC$ không bị bao hàm bởi $\neg C_7$ dựa trên $\KB$ nên ta thêm $\neg C_7$ vào $\mbC$ và thêm các phần tử của $Y_7$ và $E^-_0$. Do đó, ta có $\mbC = \{\neg C_6, \neg C_7\}$ và $E_0^- = \{\Pub_1, \Pub_2, \Pub_3\}$.
		
		\item Vì $Y_9 \subseteq E^-$ nên ta tiến hành xem xét đối với $C_9 \equiv (\PubYear < 2008) \mand (\PubYear < 2007) \mand \neg\E\Citedby.((\PubYear \geq 2008) \mand (\PubYear \geq 2010))$. Vì $\KB \models \neg C_9(a)$ với mọi $a \in E^+$ và $\bigsqcap\mbC$ không bị bao hàm bởi $\neg C_9$ dựa trên $\KB$ nên ta thêm $\neg C_9$ vào $\mbC$ và thêm các phân tử của $Y_9$ vào $E^-_0$. Do đó, ta có $\mbC = \{\neg C_6, \neg C_7, \neg C_9\}$ và $E^-_0 = \{\Pub_1, \Pub_2, \Pub_3, \Pub_5\}$. 
		
		\item Vì $E^-_0 = E^-$ nên ta có $C \equiv \bigsqcap\mbC \equiv \neg((\PubYear \geq 2008) \mand (\PubYear \geq 2010)) \mand \neg((\PubYear \geq 2008) \mand (\PubYear < 2010)) \mand \neg((\PubYear < 2008) \mand (\PubYear < 2007) \mand \neg\E\Citedby.((\PubYear \geq 2008) \mand (\PubYear \geq 2010)))$. Rút gọn $C$ ta được kết quả trả về là $C_{rs} \equiv (\PubYear < 2008) \mand [(\PubYear \geq 2007) \mor \E\Citedby.(\PubYear \geq 2010)]$.\myend
	\end{enumerate}
\end{Example}

%-------------------------------------------------------------------
\section*{Tiểu kết Chương~\ref{Chapter3}}
\addcontentsline{toc}{section}{Tiểu kết Chương~\ref{Chapter3}}
\label{sec:Chap3.Summary}
Chương này đã trình bày thuật toán làm mịn phân hoạch miền của diễn dịch trong logic mô tả (Thuật toán~\ref{alg:Partition}). Trên cơ sở đó, chúng tôi giới thiệu Thuật toán \BBCLearnS để giải quyết bài toán học khái niệm cho cơ sở tri thức trong logic mô tả. 
Ý tưởng chính của thuật toán này là sử dụng các mô hình của cơ sở tri thức kết hợp với mô phỏng hai chiều trong các mô hình đó (để mô hình hóa tính không phân biệt được) và cây quyết định (để phân lớp dữ liệu) cho việc tìm kiếm khái niệm kết quả. Tính đúng của thuật toán \BBCLearnS cũng được chứng minh thông qua bổ đề liên quan.
Thuật toán này có thể áp dụng cho một lớp lớn các logic mô tả là mở rộng của $\mathcal{ALC}_{\Sigma,\Phi}$ có tính chất mô hình hữu hạn hoặc nữa hữu hạn, trong đó $\Phi \subseteq \{\mI, \mF, \mN, \mQ, \mO, \mU, \Self\}$. Lớp các logic mày chứa nhiều logic mô tả rất hữu ích, chẳng hạn như \SHIQ (logic làm cơ sở cho OWL) và \SROIQ (logic làm cơ sở cho OWL~2) được sử dụng trong nhiều ứng dụng của Web ngữ nghĩa.
\cleardoublepage
